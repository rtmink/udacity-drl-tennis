{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Agent on Unity Environment\n",
    "\n",
    "---\n",
    "\n",
    "## Start the Environment\n",
    "\n",
    "Below assumes that one has followed the instruction on the README file such that the Unity environment is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Agents\n",
    "\n",
    "Specify the saved models to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_model_path = \"actor.pt\"\n",
    "critic_model_path = \"critic.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below to see the agents interact with the Unity environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from maddpg import Controller\n",
    "\n",
    "seed = 69\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment\n",
    "state_size = len(env_info.vector_observations[1])      # get state size\n",
    "action_size = brain.vector_action_space_size           # get action size\n",
    "num_agents = len(env_info.agents)                      # number of agents\n",
    "episodes = 21                                          # number of episodes\n",
    "\n",
    "# initialize the algorithm controller and networks\n",
    "controller = Controller(state_size, action_size, seed) \n",
    "controller.actor_local.load_state_dict(torch.load(actor_model_path, map_location=lambda storage, loc: storage))\n",
    "controller.critic_local.load_state_dict(torch.load(critic_model_path, map_location=lambda storage, loc: storage))\n",
    "\n",
    "for i_episode in range(1, episodes):\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment\n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    \n",
    "    while True:\n",
    "        actions = controller.act(states, add_noise=False)  # select an action (for each agent)\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to the environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finishes\n",
    "        scores += rewards                                  # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finishes\n",
    "            break\n",
    "\n",
    "    print('Total score (max over agents): {} for episode {}'.format(np.amax(scores), i_episode))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
